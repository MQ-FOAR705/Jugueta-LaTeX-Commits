\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{hyperref}
\setlength{\parindent}{0pt}
\setlength{\parskip}{1em}

\title{FOAR705 - Learning Journal From Week 8 to 13}
\author{Jan Jugueta - 44828020}
\date{September, October \& November 2019}

\begin{document}

\maketitle

\tableofcontents

\newpage
\section{OpenRefine Lessons}

\subsection{Creating a new OpenRefine project}

\textbf{9/9/19 - 2:01pm}

\textbf{Objective:} Create a new project

\textbf{Action:}

\begin{enumerate}
    \item Clicked on create project
    \item Selected get data from 'This Computer'
    \item Clicked on Choose Files
    \item Selected SAFI\_openrefine.csv
    \item Clicked Next
    \item Clicked Create Project
\end{enumerate}

\textbf{Error:} None.

\textbf{Result:} New project created with OpenRefine using SAFI\_openrefine.csv.

\subsection{Using Facets}

\textbf{9/9/19 - 2:11pm}

\textbf{Objective:} Use faceting to look for potential errors in data entry in the village column.

\textbf{Action:}

\begin{enumerate}
    \item Selected Text Facet in the Facet in the drop down menu from the village column
\end{enumerate}

\textbf{Error:} None.

\textbf{Result:} The facet window on the left shows all the data entries for the village column. With this view we can see the errors that have been made. Chirdozo is likely a typo. Ruca is like a typo as well. There are many entries for Ruaca - Nhamuenda. 49 is almost certainly an error, but I have no idea what it refers to so there's not much I can do about that one.

\subsection{Using clustering to detect possible typing errors}

\textbf{9/9/19 - 2:35pm}

\textbf{Objective:} To merge clusters to clean up the values in the village column

\textbf{Action:}

\begin{enumerate}
    \item Click Cluster in the village Text Facet
    \item Select the key collision method and the metaphone3 keying function
    \item Click the Merge? box beside the clusters
    \item Click Merge Selected and Recluster
    \item Tried all other Methods and Keying Functions
    \item Go back to the village Text Facet
    \item Hovered over Chirdozo and selected edit
    \item Renamed Chirdozo to Chirodzo
    \item Hovered over Ruaca-Nhamuenda and selected edit
    \item Renamed it to Ruaca.
\end{enumerate}

\textbf{Error:} None.

\textbf{Result:} There are now only 4 different values in the village column. Chirodzo, God, Ruaca and 49. Another point was that the other methods and keying functions did not find any more clusters.

\subsection{Transforming data}

\textbf{9/9/19 - 2:46pm}

\textbf{Objective:} Remove the left square brackets from the data in the items\_owned column.

\textbf{Action:}

\begin{enumerate}
    \item Clicked on the arrow at the top of the items\_owned column
    \item Select Edit Cells
    \item Select Transform...
    \item Type in \begin{verbatim}
        value.replace("[", "")]
    \end{verbatim}
    \item Click OK
\end{enumerate}

\textbf{Error:} None.

\textbf{Result:} All left brackets have been removed.

\subsection{Trim Leading and Trailing Whitespace}

\textbf{9/9/19 - 3:12pm}

\textbf{Objective:} Tidy up respondent\_wall\_type so that burntbricks and muddaub are just one value instead of two.

\textbf{Action:}

\begin{enumerate}
    \item Selected Edit cells
    \item Selected Common transforms
    \item Selected Trim leading and trailing whitespace
\end{enumerate}

\textbf{Error:} None.

\textbf{Result:} There are only four choices left in the text facet.

\subsection{Numbers}

\textbf{22/9/19 - 8:55pm}

\textbf{Objective:} Convert years\_farm column to numbers.

\textbf{Action:}

\begin{enumerate}
    \item Click the drop down arrow in the years\_farm column
    \item Click Edit cells
    \item Click Common transforms...
    \item Click To number
\end{enumerate}

\textbf{Error:} None.

\textbf{Result:} years\_farm column data converted to numbers.

\subsection{Saving your work as a script}

\textbf{22/9/19 - 9:11pm}

\textbf{Objective:} Save script in JSON format as .txt file

\textbf{Action:}

\begin{enumerate}
    \item Click on Undo / Redo
    \item Click Extract
    \item Copy the code from the window on the right hand side
    \item Paste it TextEdit
    \item Save as Plain text file
\end{enumerate}

\textbf{Error:} None.

\textbf{Result:} Script saved in JSON format as .txt file.

\subsection{Importing a script to use against another data set}

\textbf{22/9/19 - 9:14pm}

\textbf{Objective:} Import script to another data set

\textbf{Action:}

\begin{enumerate}
    \item Started a new OpenRefine project
    \item Click on Undo / Redo
    \item Click on Apply
    \item Paste the contents of the JSON .txt file
    \item Click on Perform operations
\end{enumerate}

\textbf{Error:} None.

\textbf{Result:} Script applied to new project. Data set has been cleaned.

\subsection{Exporting}

\textbf{22/9/19 - 9:22pm}

\textbf{Objective:} Export OpenRefine project

\textbf{Action:}

\begin{enumerate}
    \item Click Export
    \item Click Export project
    \item Download tar.gz file
\end{enumerate}

\textbf{Error:} None.

\textbf{Result:} Successfully exported OpenRefine project.

Answering the additional questions. There is a history folder with with change.txt files that contain records of each individual change in the data. There is also a data.zip file which contains all the data.

\subsection{Exporting Cleaned Data}

\textbf{22/9/19 - 9:27pm}

\textbf{Objective:} Export just the cleaned data

\textbf{Action:}

\begin{enumerate}
    \item Click on Export
    \item Select Comma-separated values
    \item Download .csv file
\end{enumerate}

\textbf{Error:} None.

\textbf{Result:} Successfully exported cleaned data.

\subsection{Using online resources to get help with OpenRefine}

I visited the OpenRefine documentation wiki website. I found it has useful step-by-step guides on how to perform tasks. Like other wiki sites, it is relatively easily to follow. Finding the right areas was a breeze with how it has been categorised.

\newpage
\section{OpenRefine Exercises}

\subsection{Using Facets}

\textbf{9/9/19 - 2:17pm}

\begin{enumerate}
    \item There are 19 different interview\_date values
    \item It appears as it is formatted by Text.
    \item \textbf{Objective:} Change format to Date.
    
    \textbf{Action:}
    \begin{enumerate}
        \item Clicked the drop down menu in the interview\_date column
        \item Selected Edit cells
        \item Selected Common transforms
        \item Selected To date
    \end{enumerate}
    
    \textbf{Error:} None
    
    \textbf{Result:} Data format has been changed to date. 2016-11-16T00:00:00Z is an example of the format.
    \item Most of the data was collected in November 2016.
\end{enumerate}

\subsection{Transforming data}

\textbf{9/9/19 - 2:50pm}

\textbf{Objective:} Remove the right square brackets, single quote marks and spaces from the data in the items\_owned column.

\textbf{Action:}

\begin{enumerate}
    \item Clicked on the arrow at the top of the items\_owned column
    \item Select Edit Cells
    \item Select Transform...
    \item Type in \begin{verbatim}
        value.replace("'", "")
        value.replace("]", "")
        value.replace(" ", "")
    \end{verbatim}
    \item Click OK
\end{enumerate}

\textbf{Error:} None.

\textbf{Result:} All right brackets, single quote marks and spaces have been removed.

\textbf{9/9/19 - 2:54pm}

By sorting with count we can see which are the most commonly owned items. They are the mobile phone and radio. The least commonly owned items are cars and computers.

\textbf{9/9/19 - 2:57pm}

\textbf{Objective:} Finding which month(s) farmers were more likely to lack food

\textbf{Action:}

\begin{enumerate}
    \item Select Transform... in the Edit cells drop down menu in the months\_lack\_food column.
    \item Enter expression \begin{verbatim}
        value.replace("[", "").replace("]", "").replace(" ", "").replace("'", "")
    \end{verbatim}
    \item Create Custom text facet for months\_lack\_food column.
    \item Enter expression \begin{verbatim}
        value.split(";")
    \end{verbatim}
    \item Sort by count
\end{enumerate}

\textbf{Error:} None.

\textbf{Result:} November was the most common month that farmers lacked food.

\textbf{9/9/19 - 3:04pm}

\textbf{Objective:} Clean up months\_no\_water, liv\_owned, res\_change, and no\_food\_mitigation columns.

\textbf{Action:}

\begin{enumerate}
    \item Clicked on months\_no\_water column
    \item Selected Transform...
    \item Went to the History tab
    \item Reused the last expression in history
    \item Repeated the process for liv\_owned, res\_change, and no\_food\_mitigation columns
\end{enumerate}

\textbf{Error:} None

\textbf{Result:} Cleaned up months\_no\_water, liv\_owned, res\_change, and no\_food\_mitigation columns.

\subsection{Using undo and redo}

\textbf{9/9/19 - 3:09pm}

The undo and redo functions work just like explained in the lesson.

\subsection{Filtering}

\textbf{10/9/19 - 4:48pm}

\begin{enumerate}
    \item The roof types returned are mabatipitched and mabatisloping
    \item To restrict it further, you could be more specific with the spelling.
\end{enumerate}

\subsection{Excluding entries}

\textbf{10/9/19 - 5:05pm}

Have played with the include / exclude option. A reminder that this option appears in the facet, not the filter.

\subsection{Sort}

\textbf{10/9/19 - 5:10pm}

\textbf{Objective:} Find out if there are incorrect altitudes in the gps\_Altitude column.

\textbf{Action:}

\begin{enumerate}
    \item Go to the gps\_Altitude column
    \item Select sort in the triangle drop down menu
    \item Select Sort
    \item Select numbers
    \item Select smallest first
\end{enumerate}

\textbf{Error:} None.

\textbf{Result:} There are a few 0's. This is most likely missing data that was not recorded.

\subsection{Sorting by multiple columns}

\textbf{10/9/19 - 5:18pm}

When sorting by GPS coordinates, village 49 seems to match with Chirodzo. When using the interview date, it also seems to suggest Chirodzo.

\subsection{Numbers}

\textbf{22/9/19 - 9:02pm}

Only numerals can be transformed into numbers.

\subsection{Numeric facets}

\textbf{22/9/19 - 9:04pm}

The blank and non-numeric facets were ticked, presumably because of the 'abc' and blank data.

\newpage
\section{OpenRefine Lesson Notes}

\begin{itemize}
    \item Data is often very messy. OpenRefine can help organise messy data.
    \item OpenRefine records all changes to the data.
    \item OpenRefine does not modify the original dataset.
    \item OpenRefine is open source.
    \item Facets help get an overview of the data as well as bring consistency to the data.
\end{itemize}

\section{OpenRefine Error List}

No errors occured when completing the OpenRefine exercises and lessons.

\newpage
\section{R for Social Scientists Lessons}

\subsection{Create a new project}

\textbf{9/10/19 - 1:24pm}

\textbf{Objective:} Create a new project in R Studio

\textbf{Action:}

\begin{itemize}
    \item Open RStudio
    \item Click File - New project - New directory - New project
    \item Enter the name data-carpentry
\item Click Create project
\item Click File - New File - R script
\item Click save icon and name script "script.R"
\end{itemize}

\textbf{Error:} None.

\textbf{Result:} New data-carpentry project created along with script.R

\subsection{Downloading the data and getting set up}

\textbf{9/10/19 - 1:34pm}

\textbf{Objective:} Create the directories "data", "data\_output" and "fig\_output"

\textbf{Action:} Type in the code
\begin{verbatim}
    dir.create("data")
    dir.create("data_output")
    dir.create("fig_output")
\end{verbatim}

\textbf{Error:} None.

\textbf{Result:} The three directories were created.

\section{R for Social Scientists Exercises}

\subsection{Installing additional packages using the packages tab}

\textbf{9/10/19 - 1:54pm}

\textbf{Objective:} Download tidyverse package

\textbf{Action:}
\begin{itemize}
    \item Click on Packages tab
\item Click on Install
\item Type in tidyverse
\item Click Install
\end{itemize}

\textbf{Error: None}

\textbf{Result:} Tidyverse installed, along with what looks like many other packages.

\subsection{Creating ojbects in R}

\textbf{9/10/19 - 4:36pm}

The value is still 6.175

\subsection{Comments}

\textbf{9/10/19 - 4:49pm}

\textbf{Objective:} See what happens when I create objects for width and length and get them to work with area.

\textbf{Action:} Entered the following code in:
\begin{verbatim}
    length <- 2
    width <- 1
    area <- length*witdh
\end{verbatim}

Then changed the value for length to 7.0 and width to 6.5. Retyped area.

\textbf{Error:} None.

\textbf{Result:} Area did not change after the values of length and width were changed. This is presumably because \begin{verbatim}
    area <- length*width
\end{verbatim} was not run again.

\subsection{Functions and their arguments}

\textbf{9/10/19 - 5:20pm}

Using \begin{verbatim}
    ?round
\end{verbatim} it seems that there are other functions similar to it. These include \begin{verbatim}
    ceiling(x)
    floor(x)
    trunc(x,...)
    signif(x,digits=6)
\end{verbatim}

\subsection{Vectors and data types}

\textbf{9/10/19 - 5:46pm}

If we try to mix different vectors together, R will convert them all to be the same type.

\newpage
\section{Proof of Concept - Design}

\subsection{General Thoughts}

\textbf{13/9/19 - 5:21pm}

I have received back my marks for the Elaboration Results and it has left me disheartened. I think now more than ever am I unsure about what I am doing, whether I should be aiming to stretch myself and try something ambitious or just design something that will work and assist me in my research. Honestly, I am leaning towards the latter.

Two main points of feedback for my Elaboration results are:
\begin{enumerate}
    \item I didn't detail alternatives to Voyant Tools
    \item That simply going through the articles I find in \textit{Neues Deutschland} and copying and pasting them into .txt files is not the best way to move forward
\end{enumerate}

I accept the feedback regarding the first point. I should have detailed alternatives to Voyant Tools for my textual analysis. As for the second, I would rather not automate that process for two main reasons.
\begin{enumerate}
    \item If I were to somehow automate the process of copying text from the \textit{Neues Deutschland} website, it would also copy in advertisements and other non-relevant text that would be too much of a hassle to clean up after the fact.
    \item Many results returned for the search query are not relevant at all to my research. This would only serve to save more unnecessary articles on my machine, which could skew corpus analysis at a later date. I would feel more comfortable actually \textbf{reading} every article on \textit{Neues Deutschland} before choosing which I should save and which I would not.
\end{enumerate}

\textbf{16/9/19 - 3:15pm}

Having a look at the next step for the Proof of Concept and I am finding it difficult ascertaining what I should actually be doing. It seems like the user stories that I have come up with are very similar, if not the same as the steps I had covered in Elaboration? Do I just repeat that work?

\textbf{16/9/19 - 4:02pm}

Without receiving feedback on my Proof of Concept Design with user stories, I am going to go ahead with what I have come up with. I am making the point that the collection of articles has already been done. My Proof of Concept will only be concerned with the analysis of text and storage of data.

\textbf{16/9/19 - 4:44pm}

Having completed learning how to save the textual analysis performed by Voyant Tools as a .tsv file, I now realise it is in a format that can work with OpenRefine. I may now consider using OpenRefine in my workflow to analyse the data once more.

\textbf{19/9/19 - 10:23am}

I think I need to read more about Open Semantic Desktop Search. It seems like a very powerful piece of software. For now, I am happy that it is able to do the tasks I need it to do, but I have no doubt that it probably can do so much more.

\textbf{9/10/19 - 10:23am}

After clearing some of my uni workload, I was finally able to organise a meeting with Brian. The meeting proved to be very helpful, with Brian providing me clarification on what I needed to do as part of my Proof of Concept.

My main take away from this was that the point of the Proof of Concept was to get the computer to do more work where it can, giving me the opportunity to drink more coffee (or another beverage of my choice). I realised my Proof of Concept was automating the process of getting text analysed using Voyant Tools and straight into Open Semantic Desktop Search.

I have downloaded the Voyant Tools open-source software directly on my machine. Let's see what I can do with this.

\newpage
\subsection{Proof of Concept - User Stories Testing}

\subsubsection{Identify Themes}

\textbf{16/9/19 - 4:05pm}

\textbf{Objective:} See if Voyant Tools is able to analyse a corpus of text to see if there are any themes that emerge.

\textbf{Action:}
\begin{enumerate}
    \item Go to www.voyant-tools.org
    \item Select upload
    \item Navigate to the directory on my machine where the corpus is selected
    \item Select all the .txt files that I want analysed
    \item Select reveal
\end{enumerate}

\textbf{Error:} None.

\textbf{Result:} Voyant Tools successfully analyses a corpus of text.

\subsubsection{Store Analysis}

\textbf{16/9/19 - 4:24pm}

\textbf{Objective:} Find out what can be exported as data from Voyant Tools.

\textbf{Action:} Click on every 'Export' button to see what was applicable

\textbf{Error:} None.

\textbf{Result:} The following can be exported as .tsv files:
\begin{itemize}
    \item Terms
    \item Document Terms
    \item Documents
    \item Phrases
    \item Contexts
    \item Correlations
\end{itemize}

All other analysis outputs can be exported as Visualitions in the form of a .png file.

\textbf{16/9/19 - 4:37pm}

\textbf{Objective:} Store 'Terms' as a .tsv file
\begin{enumerate}
    \item Click on Export in the Terms window in Voyant Tools
    \item Click 'export all available data as tab separated values (text)'
    \item Copy the text from the new window that opens
    \item Open TextEdit on my machine
    \item Paste text into TextEdit
    \item Save as terms.tsv in the /Jugueta/MRes/data/textualanalysis/ directory
\end{enumerate}

\textbf{Error:} None.

\textbf{Result:} New filed saved as terms.tsv

\subsubsection{Additional Notes}

\textbf{16/9/19 - 4:52pm}

\textbf{Objective:} Store additional notes I have made on the analysis onto my machine

\textbf{Action:}
\begin{enumerate}
    \item Open TextEdit
    \item Write notes
    \item Save notes a .txt file
    \item Save in the /Jugueta/MRes/notes/textualanalysis/ directory on my machine
\end{enumerate}

\textbf{Error:} None.

\textbf{Result:} Am able to use TextEdit to save notes on my machine.

\subsubsection{Create Tags}

\textbf{19/9/19 - 10:25am}

\textbf{Objective:} Create a 'stasi' tag that will be used to organise my data and notes relating to the East German Secret Police using Open Semantic Desktop Search.

\textbf{Action:}
\begin{enumerate}
    \item Launch VirtualBox VM
    \item Set the Shared Folder to /Jugueta/MRes/
    \item Start Open Semantic Desktop Search
    \item Click on the Activities menu in Open Semantic Desktop Search
    \item Click on Index documents to ensure that I am working with the right directory
    \item Click on Manage structure
    \item Click on Add new entry
    \item Enter 'stasi' for the name and select tag in Facet type
    \item Click Save
\end{enumerate}

\textbf{Error:} None.

\textbf{Result:} A 'stasi' tag is now in existence.

\subsubsection{Search My Research}

\textbf{19/9/19 - 10:59am}

\textbf{Objective:} Search for 'Hamburg' using Open Semantic Desktop Search

\textbf{Action:}
\begin{itemize}
    \item Launch VirtualBox VM
    \item Start Open Semantic Desktop Search
    \item Type in 'Hamburg' in the Search bar
    \item Click on Search
\end{itemize}

\textbf{Error:} None.

\textbf{Result:} 38 results were returned with the query 'Hamburg'. This has searched my entire MRes folder though, so I want to see if there is a way to be more succinct with the search.

\textbf{19/9/19 - 11:37am}

\textbf{Objective:} Be more succinct with my searches, targeting a specific path or folder.

\textbf{Action:}
\begin{itemize}
    \item Launch VirtualBox VM
    \item Start Open Semantic Desktop Search
    \item Type in 'Hamburg' in the Search bar
    \item In Paths, select MRes
    \item Select notes
    \item Select articles
    \item Click on Search
\end{itemize}

\textbf{Error:} None.

\textbf{Result:} Search was contained only in the articles folder. It returned 5 items.

\textbf{19/9/19 - 11:43am}

\textbf{Objective:} Figure out what is achievable in the search option settings.

\begin{itemize}
    \item Launch VirtualBox VM
    \item Start Open Semantic Desktop Search
    \item Used numerous combinations of search phrases to test the search option settings.
\end{itemize}

\textbf{Error:} None.

\textbf{Result:} Open Semantic Desktop Search has powerful bolean search operators. So it's just like MultiSearch. It also has fuzzy search options, that will return other word forms similar to the query (grammar and stemming).

\subsubsection{Tag Newspaper Articles}

\textbf{25/9/19 - 10:55am}

\textbf{Objective:} Tag 'stasi' to newspaper articles that are related to the Stasi.

\begin{itemize}
    \item Launch VirtualBox VM
    \item Start Open Semantic Desktop Search
    \item Type stasi in the search field
    \item Set the path to the newspaper directory
    \item Click on first returned result
    \item Confirm if relevant to Stasi
    \item Click the Tagging \& annotation button
    \item Go to the Tags tab
    \item Click on the stasi tag
\end{itemize}

\textbf{Error:} None.

\textbf{Result:} The newspaper article is correctly tagged with the 'stasi' tag.

\subsubsection{Tag Textual Analysis}

\textbf{25/9/19 - 11:07am}

\textbf{Objective:} Tag 'stasi' to Voyant Tools Textual analysis data that are related to the Stasi.

\begin{itemize}
    \item Launch VirtualBox VM
    \item Start Open Semantic Desktop Search
    \item Type stasi in the search field
    \item Set the path to the textual analysis directory
    \item Click on first returned result
    \item Confirm if relevant to Stasi
    \item Click the Tagging \& annotation button
    \item Go to the Tags tab
    \item Click on the stasi tag
\end{itemize}

\textbf{Error:} None.

\textbf{Result:} The data from the textual analysis is correctly tagged with the 'stasi' tag.

\subsubsection{Tag Notes}

\textbf{25/9/19 - 11:21am}

\textbf{Objective:} Tag 'stasi' to general research notes that I have written that are related to the Stasi.

\begin{itemize}
    \item Launch VirtualBox VM
    \item Start Open Semantic Desktop Search
    \item Type stasi in the search field
    \item Set the path to the notes directory
    \item Click on first returned result
    \item Confirm if relevant to Stasi
    \item Click the Tagging \& annotation button
    \item Go to the Tags tab
    \item Click on the stasi tag
\end{itemize}

\textbf{Error:} None.

\textbf{Result:} The notes are correctly tagged with the 'stasi' tag.

\newpage
\section{Misc Notes on FOAR705}

\textbf{4/6/19 - 11:06am}

I have decided to keep using this Learning Journal for the rest of the unit. I will still upload them to Cloudstor on a weekly basis for consistency. I have chosen to do this so that I will have a more comprehensive journal that I can refer back to later in the unit.

Another general note. I still think my OSP is too vague. I don't know how to make it more specific. Hopefully I will get some guidance about it today in class. I really don't have time to go to the consultation hours due to the immense workload that I have from this unit, on top with all my other units.

\end{document}
